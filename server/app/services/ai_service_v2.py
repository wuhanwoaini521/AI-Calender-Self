"""
AI Service v2 - With Function Calling / Tools / MCP Support

This service integrates with OpenAI-compatible APIs and supports:
- Tool calling (Function Calling)
- Skills (multi-step tool orchestration)
- MCP (Model Context Protocol)
"""

import json
from typing import List, Dict, Any, Optional, AsyncGenerator
from datetime import datetime, timedelta
from openai import AsyncOpenAI

from ..tools.registry import registry as tool_registry
from ..skills.registry import skill_registry, SkillContext
from ..mcp.server import MCPServer
from ..core.config import get_settings


class AIServiceV2:
    """AI Service with Function Calling and MCP support"""
    
    def __init__(self):
        settings = get_settings()
        
        # Initialize OpenAI client (supports OpenRouter, etc.)
        self.client = AsyncOpenAI(
            base_url=settings.OPENAI_BASE_URL,
            api_key=settings.OPENAI_API_KEY,
        )
        self.model = settings.OPENAI_MODEL
        self.mcp_server = MCPServer()
        
        # System prompt for the AI
        self.system_prompt = """ä½ æ˜¯AIæ—¥å†åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç®¡ç†æ—¥ç¨‹ã€‚

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼Œå¿…é¡»æ ¹æ®ç”¨æˆ·æ„å›¾è°ƒç”¨ç›¸åº”å·¥å…·ï¼š
- create_event: åˆ›å»ºæ–°çš„æ—¥å†äº‹ä»¶/ä¼šè®®/æ—¥ç¨‹
- get_events: æŸ¥è¯¢æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ—¥ç¨‹
- update_event: æ›´æ–°å·²æœ‰äº‹ä»¶
- delete_event: åˆ é™¤äº‹ä»¶
- find_free_slots: æŸ¥æ‰¾ç©ºé—²æ—¶é—´æ®µ
- detect_conflicts: æ£€æµ‹æ—¥ç¨‹å†²çª
- generate_schedule: ç”Ÿæˆä¼˜åŒ–æ—¥ç¨‹
- optimize_schedule: åˆ†æå¹¶å»ºè®®æ—¥ç¨‹ä¼˜åŒ–
- suggest_breaks: å»ºè®®ä¼‘æ¯æ—¶é—´

å¼ºåˆ¶è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
1. å½“ç”¨æˆ·è¯´"å¼€ä¼š"ã€"æœ‰ä¸ªä¼š"ã€"åˆ›å»ºäº‹ä»¶"ç­‰åŒ…å«æ—¶é—´è¡¨è¾¾çš„è¯·æ±‚æ—¶ï¼Œå¿…é¡»è°ƒç”¨ create_event å·¥å…·ï¼Œä¸è¦åªå›å¤æ–‡å­—ã€‚
2. æ—¶é—´è§£æè§„åˆ™ï¼š
   - "æ˜å¤©" = å½“å‰æ—¥æœŸ + 1å¤©
   - "ä»Šå¤©" = å½“å‰æ—¥æœŸ
   - "åå¤©" = å½“å‰æ—¥æœŸ + 2å¤©
   - "ä¸‹åˆä¸‰ç‚¹" = 15:00
   - "ä¸Šåˆä¹ç‚¹" = 09:00
   - "12ç‚¹" = 12:00
   - "æ™šä¸Š8ç‚¹" = 20:00
3. é»˜è®¤ä¼šè®®æ—¶é•¿60åˆ†é’Ÿï¼ˆ1å°æ—¶ï¼‰

ç¤ºä¾‹è°ƒç”¨ï¼š
ç”¨æˆ·ï¼š"æ˜å¤©ä¸‹åˆä¸‰ç‚¹å¼€ä¼š"
è°ƒç”¨å‚æ•°ï¼š
- title: "ä¼šè®®"
- start_time: "2026-02-06T15:00:00"
- end_time: "2026-02-06T16:00:00"

æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD
æ—¶é—´æ ¼å¼ï¼šHH:MM (24å°æ—¶åˆ¶ï¼ŒISO 8601æ ¼å¼)
"""
    
    async def chat(
        self,
        messages: List[Dict[str, str]],
        user_id: str,
        context: Optional[Dict[str, Any]] = None,
        use_tools: bool = True,
    ) -> AsyncGenerator[str, None]:
        """
        Chat with function calling support
        
        Yields text chunks or tool results as they arrive
        """
        # Build messages
        chat_messages = [
            {"role": "system", "content": self.system_prompt},
            *messages,
        ]
        
        # Add context if available
        if context:
            context_str = self._format_context(context)
            chat_messages.insert(1, {
                "role": "system",
                "content": f"Current context:\n{context_str}"
            })
        
        # Get available tools
        tools = self.mcp_server.get_openai_tools() if use_tools else None
        print(f"[DEBUG] Available tools: {[t['function']['name'] for t in (tools or [])]}")
        print(f"[DEBUG] Messages: {chat_messages}")
        
        # Call LLM
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=chat_messages,
            tools=tools,
            tool_choice="auto" if use_tools else None,
            stream=True,
        )
        
        # Process streaming response
        current_tool_calls = {}
        
        async for chunk in response:
            delta = chunk.choices[0].delta
            
            # Handle content
            if delta.content:
                yield json.dumps({"type": "text", "content": delta.content})
            
            # Handle tool calls
            if delta.tool_calls:
                print(f"[DEBUG] Tool call delta: {delta.tool_calls}")
                for tc in delta.tool_calls:
                    index = tc.index
                    
                    if index not in current_tool_calls:
                        current_tool_calls[index] = {
                            "id": tc.id,
                            "function": {"name": "", "arguments": ""},
                        }
                    
                    if tc.function.name:
                        current_tool_calls[index]["function"]["name"] = tc.function.name
                        print(f"[DEBUG] Tool name: {tc.function.name}")
                    
                    if tc.function.arguments:
                        current_tool_calls[index]["function"]["arguments"] += tc.function.arguments
        
        # Execute tool calls
        tool_results = []
        print(f"[DEBUG] Current tool calls: {current_tool_calls}")
        if current_tool_calls:
            for tc in current_tool_calls.values():
                tool_name = tc["function"]["name"]
                try:
                    arguments = json.loads(tc["function"]["arguments"])
                except json.JSONDecodeError:
                    arguments = {}
                
                # Add user_id to arguments
                arguments["user_id"] = user_id
                
                # Execute tool
                result = await tool_registry.execute(tool_name, **arguments)
                
                # Store result for later
                tool_results.append({
                    "tool": tool_name,
                    "result": result,
                })
                
                # Yield tool result
                yield json.dumps({
                    "type": "tool_call",
                    "tool": tool_name,
                    "success": result.success,
                    "result": result.data if result.success else {"error": result.error},
                    "message": result.message,
                })
            
            # After tool execution, continue the conversation with results
            # Add assistant message with tool calls
            assistant_msg = {"role": "assistant", "content": None, "tool_calls": []}
            for i, tc in enumerate(current_tool_calls.values()):
                assistant_msg["tool_calls"].append({
                    "id": tc.get("id", f"call_{i}"),
                    "type": "function",
                    "function": tc["function"],
                })
            chat_messages.append(assistant_msg)
            
            # Add tool results
            for i, tr in enumerate(tool_results):
                tc_id = list(current_tool_calls.values())[i].get("id", f"call_{i}")
                chat_messages.append({
                    "role": "tool",
                    "tool_call_id": tc_id,
                    "content": json.dumps({
                        "success": tr["result"].success,
                        "message": tr["result"].message,
                        "data": tr["result"].data if tr["result"].success else {"error": tr["result"].error},
                    }, ensure_ascii=False),
                })
            
            # Get final response from AI
            final_response = await self.client.chat.completions.create(
                model=self.model,
                messages=chat_messages,
                stream=True,
            )
            
            async for chunk in final_response:
                if chunk.choices[0].delta.content:
                    yield json.dumps({"type": "text", "content": chunk.choices[0].delta.content})
    
    async def chat_with_skills(
        self,
        messages: List[Dict[str, str]],
        user_id: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> AsyncGenerator[str, None]:
        """
        Chat with skill detection and execution
        
        The AI can choose to use high-level skills for complex tasks
        """
        # First, determine if we should use a skill
        user_message = messages[-1]["content"] if messages else ""
        intent = await self._detect_intent(user_message)
        print(f"[DEBUG] Intent detection for '{user_message}': {intent}")
        
        # æ£€æµ‹æ˜¯å¦æ˜¯åˆ›å»ºäº‹ä»¶è¯·æ±‚
        if self._is_create_event_intent(user_message):
            print(f"[DEBUG] Detected create event intent")
            async for chunk in self._handle_create_event(messages, user_message, user_id, context):
                yield chunk
            return
        
        if intent["use_skill"] and intent["skill"]:
            # Execute skill directly
            skill_context = SkillContext(
                user_id=user_id,
                current_date=datetime.utcnow(),
                selected_date=datetime.strptime(context.get("selected_date"), "%Y-%m-%d") if context and "selected_date" in context else None,
            )
            
            # Yield skill start
            yield json.dumps({
                "type": "skill_start",
                "skill": intent["skill"],
            })
            
            # Execute skill
            result = await skill_registry.execute(
                intent["skill"],
                skill_context,
                **intent.get("params", {}),
            )
            
            # Yield skill result
            yield json.dumps({
                "type": "skill_result",
                "skill": intent["skill"],
                "success": result.success,
                "message": result.message,
                "data": result.data,
                "steps": [s.model_dump(mode='json') for s in result.steps],
            })
            
            # Generate natural language response
            nl_response = await self._generate_nl_response(
                messages,
                result.message,
                context,
            )
            
            async for chunk in nl_response:
                yield chunk
        else:
            # Fall back to regular tool-based chat
            async for chunk in self.chat(messages, user_id, context, use_tools=True):
                yield chunk
    
    def _is_create_event_intent(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯åˆ›å»ºäº‹ä»¶çš„æ„å›¾"""
        message_lower = message.lower()
        event_keywords = ["ä¼šè®®", "meeting", "ä¼š", "æ—¥ç¨‹", "äº‹ä»¶", "event", "appointment", "çº¦ä¼š"]
        time_keywords = ["ç‚¹", "æ˜å¤©", "ä»Šå¤©", "åå¤©", "ä¸Šåˆ", "ä¸‹åˆ", "æ™šä¸Š", "æ—©ä¸Š"]
        
        has_event = any(word in message_lower for word in event_keywords)
        has_time = any(word in message_lower for word in time_keywords)
        
        return has_event and has_time
    
    async def _handle_create_event(
        self,
        messages: List[Dict[str, str]],
        user_message: str,
        user_id: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> AsyncGenerator[str, None]:
        """å¤„ç†åˆ›å»ºäº‹ä»¶è¯·æ±‚ - ä½¿ç”¨LLMè§£æ"""
        from ..tools.registry import registry as tool_registry
        
        # è·å–å½“å‰æ—¥æœŸï¼ˆæ”¯æŒé©¼å³°å’Œä¸‹åˆ’çº¿ä¸¤ç§å‘½åï¼‰
        current_date = None
        if context:
            current_date = context.get("current_date") or context.get("currentDate")
        if not current_date:
            current_date = datetime.utcnow().strftime("%Y-%m-%d")
        print(f"[DEBUG] Current date: {current_date}, context: {context}")
        
        # è®¡ç®—æ˜å¤©çš„æ—¥æœŸ
        today = datetime.strptime(current_date, "%Y-%m-%d")
        tomorrow = (today + timedelta(days=1)).strftime("%Y-%m-%d")
        
        # è®© AI è§£ææ—¶é—´å‚æ•°
        parse_prompt = f"""è§£æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æ—¶é—´è¡¨è¾¾ï¼Œæå–äº‹ä»¶ä¿¡æ¯ã€‚

å½“å‰æ—¥æœŸï¼š{current_date}
æ˜å¤©æ—¥æœŸï¼š{tomorrow}
ç”¨æˆ·è¾“å…¥ï¼š"{user_message}"

è§„åˆ™ï¼š
1. æ—¥æœŸï¼š
   - å¦‚æœæåˆ°"æ˜å¤©"ï¼Œä½¿ç”¨æ—¥æœŸ {tomorrow}
   - å¦‚æœæåˆ°"ä»Šå¤©"ï¼Œä½¿ç”¨æ—¥æœŸ {current_date}
   - å¦‚æœæåˆ°"åå¤©"ï¼Œä½¿ç”¨æ—¥æœŸ {(today + timedelta(days=2)).strftime("%Y-%m-%d")}

2. æ—¶é—´è½¬æ¢ï¼š
   - "ä¸‹åˆä¸‰ç‚¹" æˆ– "ä¸‹åˆ3ç‚¹" = 15:00
   - "ä¸Šåˆä¹ç‚¹" æˆ– "ä¸Šåˆ9ç‚¹" = 09:00
   - "12ç‚¹" = 12:00
   - "æ™šä¸Š8ç‚¹" = 20:00

3. æ—¶é•¿é»˜è®¤60åˆ†é’Ÿ

å¿…é¡»è¿”å›æœ‰æ•ˆçš„æ—¥æœŸæ—¶é—´æ ¼å¼ï¼Œç¤ºä¾‹ï¼š
{{"title": "ä¼šè®®", "start_time": "{tomorrow}T15:00:00", "end_time": "{tomorrow}T16:00:00"}}

åªè¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"""

        try:
            print(f"[DEBUG] Calling LLM for time parsing...")
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯æ—¶é—´è§£æåŠ©æ‰‹ï¼Œåªè¾“å‡ºJSONæ ¼å¼çš„ç»“æœã€‚"},
                    {"role": "user", "content": parse_prompt},
                ],
                timeout=10,  # æ·»åŠ  10 ç§’è¶…æ—¶
            )
            print(f"[DEBUG] LLM call completed")
            
            content = response.choices[0].message.content
            print(f"[DEBUG] LLM response: {content}")
            
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{[^}]*\}', content, re.DOTALL)
            if json_match:
                parsed = json.loads(json_match.group())
            else:
                parsed = json.loads(content)
            
            print(f"[DEBUG] Parsed event: {parsed}")
            
            # éªŒè¯å¿…è¦å­—æ®µï¼Œå¦‚æœ AI è¿”å›ç©ºå€¼ï¼Œä½¿ç”¨è§„åˆ™è§£æä½œä¸ºå¤‡ç”¨
            if not parsed.get("start_time") or not parsed.get("end_time"):
                print(f"[DEBUG] AI returned empty time, using fallback parser")
                parsed = self._parse_event_request(user_message, current_date)
                print(f"[DEBUG] Fallback parsed: {parsed}")
            
            # è°ƒç”¨åˆ›å»ºäº‹ä»¶å·¥å…·
            result = await tool_registry.execute(
                "create_event",
                user_id=user_id,
                title=parsed.get("title", "æ–°äº‹ä»¶"),
                start_time=parsed["start_time"],
                end_time=parsed["end_time"],
            )
            
            # è¾“å‡ºå·¥å…·è°ƒç”¨ç»“æœ
            yield json.dumps({
                "type": "tool_call",
                "tool": "create_event",
                "success": result.success,
                "result": result.data if result.success else {"error": result.error},
                "message": result.message,
            })
            
            # ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
            if result.success:
                response_text = f"âœ… å·²ä¸ºæ‚¨åˆ›å»ºäº‹ä»¶ï¼š{parsed.get('title')}\nğŸ“… æ—¶é—´ï¼š{parsed.get('start_time')} è‡³ {parsed.get('end_time')}"
            else:
                response_text = f"âŒ åˆ›å»ºäº‹ä»¶å¤±è´¥ï¼š{result.error}"
            
            yield json.dumps({"type": "text", "content": response_text})
            
        except Exception as e:
            print(f"[DEBUG] Error in _handle_create_event: {e}")
            yield json.dumps({"type": "text", "content": f"åˆ›å»ºäº‹ä»¶æ—¶å‡ºé”™ï¼š{str(e)}"})
    
    async def _detect_intent(self, message: str) -> Dict[str, Any]:
        """Detect user intent to determine if we should use a skill"""
        message_lower = message.lower()
        
        # Check for skill triggers
        if any(word in message_lower for word in ["æˆ‘çš„æ—¥ç¨‹", "schedule", "ä»Šå¤©æœ‰ä»€ä¹ˆ", "ä»Šå¤©å®‰æ’"]):
            return {
                "use_skill": True,
                "skill": "schedule_management",
                "params": {},
            }
        
        # æ£€æµ‹åˆ›å»ºäº‹ä»¶çš„æ„å›¾ - åŒ…å«æ—¶é—´+ä¼šè®®/äº‹ä»¶/æ´»åŠ¨çš„è¡¨è¾¾
        create_keywords = ["åˆ›å»º", "æ–°å»º", "æ·»åŠ ", "å®‰æ’", "schedule", "create", "add", "book"]
        event_keywords = ["ä¼šè®®", "meeting", "ä¼š", "event", "æ´»åŠ¨", "æ—¥ç¨‹", "äº‹æƒ…", "çº¦ä¼š", "appointment"]
        time_keywords = ["ç‚¹", "å·", "å·", "æ˜å¤©", "ä»Šå¤©", "åå¤©", "ä¸‹åˆ", "ä¸Šåˆ", "æ™šä¸Š", "æ—©ä¸Š", 
                        "am", "pm", "morning", "afternoon", "evening", "tomorrow", "today"]
        
        has_create = any(word in message_lower for word in create_keywords)
        has_event = any(word in message_lower for word in event_keywords)
        has_time = any(word in message_lower for word in time_keywords)
        
        # å¦‚æœåŒ…å«äº‹ä»¶å…³é”®è¯+æ—¶é—´ï¼Œè®¤ä¸ºæ˜¯åˆ›å»ºäº‹ä»¶ï¼ˆè®©AIç”¨å·¥å…·è°ƒç”¨å†³å®šï¼‰
        if has_event and has_time:
            # ä½¿ç”¨å·¥å…·è°ƒç”¨ç›´æ¥åˆ›å»ºï¼Œä¸èµ°æŠ€èƒ½è·¯ç”±
            return {"use_skill": False}
        
        # ä»…æŸ¥æ‰¾ç©ºé—²æ—¶é—´/è§„åˆ’ä¼šè®®æ—¶é—´ï¼Œä¸åˆ›å»º
        if any(word in message_lower for word in ["ä»€ä¹ˆæ—¶å€™æœ‰ç©º", "find time", "çº¦æ—¶é—´", "available", "æœ‰ç©º"]):
            return {
                "use_skill": True,
                "skill": "meeting_planning",
                "params": {},
            }
        
        if any(word in message_lower for word in ["è®¡åˆ’", "plan", "å®‰æ’ä»»åŠ¡", "daily plan"]):
            return {
                "use_skill": True,
                "skill": "daily_planning",
                "params": {},
            }
        
        return {"use_skill": False}
    
    def _parse_event_request(self, message: str, current_date: str) -> Dict[str, str]:
        """ä½¿ç”¨è§„åˆ™è§£æäº‹ä»¶è¯·æ±‚ï¼ˆä½œä¸ºAIè§£æçš„å¤‡ç”¨ï¼‰"""
        import re
        
        message_lower = message.lower()
        
        # è§£ææ—¥æœŸ
        target_date = datetime.strptime(current_date, "%Y-%m-%d")
        if "æ˜å¤©" in message:
            target_date += timedelta(days=1)
        elif "åå¤©" in message:
            target_date += timedelta(days=2)
        
        # è§£ææ—¶é—´
        hour = 9
        minute = 0
        
        # åŒ¹é…æ—¶é—´
        time_patterns = [
            (r'(\d+):(\d+)', lambda m: (int(m.group(1)), int(m.group(2)))),
            (r'(\d+)ç‚¹(\d+)åˆ†', lambda m: (int(m.group(1)), int(m.group(2)))),
            (r'(\d+)ç‚¹', lambda m: (int(m.group(1)), 0)),
        ]
        
        for pattern, extractor in time_patterns:
            match = re.search(pattern, message)
            if match:
                hour, minute = extractor(match)
                break
        
        # å¤„ç†ä¸Šåˆ/ä¸‹åˆ/æ™šä¸Š
        if "ä¸‹åˆ" in message and hour < 12:
            hour += 12
        elif "æ™šä¸Š" in message and hour < 12:
            hour += 12
        elif "ä¸Šåˆ" in message and hour > 12:
            hour -= 12
        
        hour = max(0, min(23, hour))
        minute = max(0, min(59, minute))
        
        start_dt = target_date.replace(hour=hour, minute=minute)
        end_dt = start_dt + timedelta(minutes=60)
        
        # æå–æ ‡é¢˜
        title = "ä¼šè®®"
        if "çº¦ä¼š" in message:
            title = "çº¦ä¼š"
        elif "èšé¤" in message:
            title = "èšé¤"
        elif "æ´»åŠ¨" in message:
            title = "æ´»åŠ¨"
        
        return {
            "title": title,
            "start_time": start_dt.strftime("%Y-%m-%dT%H:%M:%S"),
            "end_time": end_dt.strftime("%Y-%m-%dT%H:%M:%S"),
        }
    
    async def _generate_nl_response(
        self,
        messages: List[Dict[str, str]],
        skill_result: str,
        context: Optional[Dict[str, Any]],
    ) -> AsyncGenerator[str, None]:
        """Generate natural language response based on skill result"""
        prompt = f"""Based on the following skill execution result, provide a helpful natural language response:

User message: {messages[-1]['content'] if messages else ''}

Skill result: {skill_result}

Respond in a helpful, conversational manner."""
        
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "You are a helpful calendar assistant."},
                {"role": "user", "content": prompt},
            ],
            stream=True,
        )
        
        async for chunk in response:
            if chunk.choices[0].delta.content:
                yield json.dumps({
                    "type": "text",
                    "content": chunk.choices[0].delta.content,
                })
    
    async def mcp_handle(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle MCP request"""
        return await self.mcp_server.handle(request)
    
    def _format_context(self, context: Dict[str, Any]) -> str:
        """Format context for the AI"""
        parts = []
        
        if "current_date" in context:
            current_date = context['current_date']
            parts.append(f"Current date: {current_date}")
            # Add day of week info
            try:
                dt = datetime.strptime(current_date, "%Y-%m-%d")
                weekdays = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
                parts.append(f"Today is: {weekdays[dt.weekday()]}")
            except:
                pass
        
        if "selected_date" in context:
            parts.append(f"Selected date: {context['selected_date']}")
        
        if "events" in context and context["events"]:
            parts.append(f"Number of existing events: {len(context['events'])}")
            for event in context["events"][:5]:
                parts.append(f"  - {event.get('title', 'Untitled')} at {event.get('startTime', 'unknown')}")
        
        # Add timezone info
        parts.append("Timezone: UTC")
        
        return "\n".join(parts)
    
    def get_available_tools(self) -> List[Dict[str, Any]]:
        """Get list of available tools"""
        return [t.to_dict() for t in tool_registry.list_tools()]
    
    def get_available_skills(self) -> List[Dict[str, Any]]:
        """Get list of available skills"""
        return [s.to_dict() for s in skill_registry.list_skills()]


# Global instance
ai_service_v2 = AIServiceV2()
